---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>
# Home
&emsp;&emsp;Fei Ma is currently a Researcher and Principal InvestigatorÂ at Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), also known as Guangming Laboratory. He leads a research team of over 10 members, focusing on cutting-edge areas including affective computing, AIGC, human motion generation, and multimodal large models. Prior to joining Guangming Laboratory, he served as a Senior Engineer at Huawei Cloud, where he gained substantial industry experience.

&emsp;&emsp;He received the B.S. degree from the University of Electronic Science and Technology of China (UESTC) in 2017, ranking first among 363 students in his major. He earned his Ph.D. degree from Tsinghua University in 2022 under the supervision of Prof. Lin Zhang. He maintains close collaborations with renowned scholars including Prof. Fei Richard Yu (Member of the Academia Europaea, Fellow of the Canadian Academy of Engineering (CAE), Engineering Institute of Canada (EIC), IEEE, and IET) and Prof. Fuji Ren (Academician of The Engineering Academy of Japan and EU Academy of Sciences, fellow of The Japan Federation of Engineering Societies, IEICE, and CAAI).

&emsp;&emsp;Currently, he is actively looking for interns and visiting students (online or offline) who are passionate about the above research areas. Interested candidates are welcome to contact via email.

<span class='anchor' id='-xl'></span>
# ğŸ“£ Recent News (2025)

| Date       | Achievement                                                                 |
| :-------------------: | :-------------------------------: |
| May 2025   | Paper accepted by **IEEE Transactions on Affective Computing** (Yifan & Yukan) |
| May 2025   | Paper accepted by **ACL 2025** (Congzhi)                                     |
| May 2025   | Paper accepted by **Information Fusion**                                     |
| Apr 2025   | 3 papers accepted by **IJCAI 2025** (Haiwei & Chenyang)                      |
| Apr 2025   | Paper accepted by **ICMR 2025** (Yifan)                                      |
| Mar 2025   | 3 papers accepted by **ICME 2025** (Tao Feng, Xin Zhang, Yang Xiang)         |
| Mar 2025   | Paper accepted by **IEEE TPAMI** (Hongwei)                                  |  

<span class='anchor' id='-pub'></span>

# ğŸ“ Publication 

* represents the first author, # represents the corresponding author

### **<span style="font-size: 1.2em; color: #2E86C1;">Journal Papers</span>** 
1) <strong>F. Ma</strong>*, Y. Li, Y. Xie, Y. He, Y. Zhang, H. Ren, Z. Liu, W. Yao, F. Ren, F. Yu, S. Ni. A Review of Human Emotion Synthesis Based on Generative Technology. IEEE Transactions on Affective Computing, 2025. (IF: 9.6)

2) H. Hou, <strong>F. Ma</strong>*, Z. Li, F. Yu. VisualRWKV-HM: Enhancing Linear Visual-Language Models via Hybrid Mixing. Information Fusion, 2025. (IF: 14.8)

3) H. Ren, Y. Zhou, J. Zhu, X. Lin, H. Fu, Y. Huang, Y. Fang, <strong>F. Ma</strong>, H. Yu, B. Cheng. Rethinking Efficient and Effective point-based Networks for Event Camera Classification and Regression. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2025. (IF: 20.8)

4) S. Chen, Z. Wu, K. Zhang, C. Li, B. Zhang, <strong>F. Ma</strong>, F. Yu, Q. Li. Exploring embodied multimodal large models: Development, datasets, and future directions. Information Fusion, 2025. (IF: 14.8)

5) <strong>F. Ma</strong>*, Y. Yuan, Y. Xie, H. Ren, I. Liu, Y. He, F. Ren, F. Yu, S. Ni. Generative Technology for Human Emotion Recognition: A Scoping Review. Information Fusion, 2024. (IF: 14.8)

6) C. Wang, H. Yu, X. Li, <strong>F. Ma</strong>, X. Wang, T. Taleb, V. Leung. Dependency-Aware Microservice Deployment for Edge Computing: A Deep Reinforcement Learning Approach with Network Representation. IEEE Transactions on Mobile Computing, 2024. (IF: 7.7)

7) Y. Liu, H. Hou, <strong>F. Ma #</strong>, S. Ni, F. Yu. MLLM-TA: Leveraging Multimodal Large Language Models for Precise Temporal Video Grounding. IEEE Signal Processing Letters, 2024. (IF: 3.2)

### **<span style="font-size: 1.2em; color: #2E86C1;">Selected Conference Papers</span>** 
1) C. Zhang, J. Peng, Z. Wang, Y. Lai, H. Sun, H. Chang, <strong>F. Ma</strong>, W. Yu. VReST: Enhancing Reasoning in Large Vision-Language Models through Tree Search and Self-Reward Mechanism. ACL 2025. (CCF A)

2) H. Xue, Z. Zhang, M. Li, Z. Dai, F. Yu, <strong>F. Ma #</strong>, Z. Wu. VideoHumanMIB: Unlocking Appearance Decoupling for Video Human Motion In-betweening. IJCAI 2025. (CCF A)

3) W. Feng, Y. Zhu, R. Zhang, C. Wang, <strong>F. Ma</strong>, X. Wang, X. Li. Active Multimodal Distillation for Few-shot Action Recognition. IJCAI 2025. (CCF A)

4) G. Chen, Y. He, M. Yu, F. Yu, G. Xu, <strong>F. Ma</strong>, M. Li, G. Zhou. Inter3D: A Benchmark and Strong Baseline for Human-Interactive 3D Object Reconstruction. IJCAI 2025. (CCF A)

5) Y. Xie, <strong>F. Ma</strong>*, Y. Bin, Y. He, F. Yu. Audio-Driven Talking Face Video Generation with Joint Uncertainty Learning. ACM ICMR 2025. 

6) Y. Xie, T. Feng, X. Zhang, X. Luo, Z. Guo, W. Yu, H. Chang, <strong>F. Ma #</strong>, F. Yu. PointTalk: Audio-Driven Dynamic Lip Point Cloud for 3D Gaussian-based Talking Head Synthesis. AAAI 2025. (CCF A)

7) X. Xiang, Z. Dai, H. Xue, D. Wang, M. Li, Y. Yue, <strong>F. Ma #</strong>, W. Yu, H. Chang, F. Yu. ReMask-Animate: Refined Character Image Animation Using Mask-Guided Adapters. AAAI 2025. (CCF A)

8) L. Wang, S. Shi, <strong>F. Ma</strong>, F. Yu, P. Li, Y. He. Subgraph Invariant Learning towards Large-scale Graph Node Classification. AAAI 2025. (CCF A)

9) X. Luo, X. Zhang, Y. Xie, X. Tong, W. Yu, H. Chang, <strong>F. Ma #</strong>, F. Yu. CodeSwap: Symmetrically Face Swapping Based on Prior Codebook. ACM MM 2024. (CCF A)

10) L. Xiong, X. Cheng, J. Tan, X. Wu, X. Li, L. Zhu, <strong>F. Ma</strong>, M. Li, H. Xu, Z. Hu. SegTalker: Segmentation-based Talking Face Generation with Mask-guided Local Editing. ACM MM 2024. (CCF A)

### **<span style="font-size: 1.2em; color: #2E86C1;">Selected Chinese Patents</span>** 
1) <strong>é©¬é£</strong>*ï¼Œå¾æ´ªæ³¢ï¼Œè°¢é•¿å²­ï¼Œå“ä¸€ç‘¶ï¼Œç½—å¥•æ˜ï¼Œæé˜³ï¼Œçºªå¥•æ³“ã€‚ä¸€ç§åŸºäºå¤šæ¨¡æ€å¤§æ¨¡å‹çš„è·Œå€’æ£€æµ‹æ–¹æ³•ã€ç³»ç»Ÿã€ç»ˆç«¯åŠå­˜å‚¨ä»‹è´¨ã€‚202510512556.7

2) <strong>é©¬é£</strong>*ï¼Œå“ä¸€ç‘¶ï¼Œæ–½æ–¯ï¼Œè‘£æ·³å…‰ã€‚ä¸€ç§ä¸ªæ€§åŒ–æ•°å­—äººé¢„é—®è¯Šå¹³å°ã€‚202411030663.8 

3) <strong>é©¬é£</strong>*ï¼Œå“ä¸€ç‘¶ï¼Œä¾¯çš“æ–‡ï¼Œå°¹ä¸œå¯Œï¼Œææµ·é¹ã€‚ä¸€ç§æ™ºèƒ½é™ªæŠ¤æ–¹æ³•ã€æ™ºèƒ½é™ªæŠ¤ç³»ç»ŸåŠè®¡ç®—æœºå­˜å‚¨ä»‹è´¨ã€‚202411159025.6

4) <strong>é©¬é£</strong>*ï¼Œå¾æ´ªæ³¢ï¼Œå“ä¸€ç‘¶ï¼Œè‘£æ·³å…‰ï¼Œæ–½æ–¯ã€‚ä¸€ç§åŸºäºå¤šæ™ºèƒ½ä½“çš„å¾®çŸ­å‰§è‡ªåŠ¨åŒ–ç”Ÿæˆæ–¹æ³•ã€ç³»ç»ŸåŠç»ˆç«¯ã€‚202411315872.7

5) <strong>é©¬é£</strong>*ï¼Œå½­äº®ï¼Œææ˜ç£Šï¼Œæ€€å®å…´ã€‚æ•°å­—äººè§†é¢‘çš„ç”Ÿæˆæ–¹æ³•ã€è£…ç½®ã€è®¾å¤‡åŠå­˜å‚¨ä»‹è´¨ã€‚202310429308.7

6) <strong>é©¬é£</strong>*ï¼Œå½­äº®ï¼Œææ˜ç£Šï¼Œæ€€å®å…´ã€‚æ•°å­—äººå¤šåª’ä½“èµ„æºçš„ç”Ÿæˆæ–¹æ³•ã€è£…ç½®ã€è®¾å¤‡åŠå­˜å‚¨ä»‹è´¨ã€‚202310389438.2

7) <strong>é©¬é£</strong>*ï¼Œææ˜ç£Šï¼Œåˆ˜è¾‰ï¼Œæ¨æ˜Œé¹ã€‚ä¸€ç§è¯„ä¼°æ–¹æ³•ã€è£…ç½®åŠè®¾å¤‡ã€‚202310934271.3

8) <strong>é©¬é£</strong>*ï¼Œé™ˆå¿—æ¯…ï¼Œææ˜ç£Šï¼Œæ€€å®å…´ã€‚ä¸€ç§è™šæ‹Ÿå½¢è±¡çš„ç®¡ç†æ–¹æ³•åŠç›¸å…³ç³»ç»Ÿã€‚202310486823.9

9) <strong>é©¬é£</strong>*ï¼Œææ˜ç£Šï¼Œæ€€å®å…´ï¼Œæˆ´å®—å®ã€‚ä¸€ç§æ•°å­—äººç»‘å®šè¯„ä¼°æ–¹æ³•ã€‚202311218488.0

10) æå›½å¥ï¼Œ<strong>é©¬é£</strong>*ï¼Œå¾æ´ªæ³¢ï¼Œå“ä¸€ç‘¶ï¼Œè°¢é•¿å²­ï¼Œæœ±æµ·ä¿Šï¼Œèµµè±«é„‚ï¼Œèƒ¡èµ«ã€‚ä¸€ç§åŸºäºå¤§æ¨¡å‹çš„æ°´åˆ©æ™ºæ…§è¯­éŸ³äº¤äº’æ–¹æ³•ã€ç³»ç»Ÿã€ç»ˆç«¯åŠå­˜å‚¨ä»‹è´¨ã€‚202510512558.6

11) å¼ é‘«ï¼Œ<strong>é©¬é£</strong>*ï¼Œå“ä¸€ç‘¶ï¼ŒèŠ±éœ–ã€‚ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹ç”Ÿæˆè¯­ä¹‰æ©ç çš„å¤šæ¨¡æ€äººè„¸ç¼–è¾‘æ–¹æ³•ã€‚202411056500.7 

12) è°¢å¥•å‡¡ï¼Œ<strong>é©¬é£</strong>*ï¼Œå“ä¸€ç‘¶ï¼Œç”°ç”„ã€‚ä¸€ç§åŸºäºç¥ç»è¾å°„åœºçš„è¯­éŸ³é©±åŠ¨æ•°å­—äººè§†é¢‘ç”Ÿæˆæ–¹æ³•ã€‚202411071122.X 

13) ç½—å‘é˜³ï¼Œ<strong>é©¬é£</strong>*ï¼Œå¾æ´ªæ³¢ï¼Œå“ä¸€ç‘¶ï¼Œåˆ˜æ´²ï¼Œè‘£å›å¿ƒã€‚ä¸€ç§å…·æœ‰ä¸€è‡´æ€§æ•…äº‹æ’ç”»ç”Ÿæˆçš„æ¡†æ¶ã€‚202411242121.7

14) è‘£å›å¿ƒï¼Œ<strong>é©¬é£</strong>*ï¼Œè´ºé¢–ï¼Œè‘£æ·³å…‰ï¼Œæ–½æ–¯ï¼Œä¾¯çš“æ–‡ã€‚ç½‘ç«™ç½‘é¡µä¸»é¢˜é£æ ¼åˆ‡æ¢æ–¹æ³•ã€è£…ç½®ã€è®¡ç®—æœºè®¾å¤‡åŠå­˜å‚¨ä»‹è´¨ã€‚202411989061.5 

15) å½­äº®ï¼Œ<strong>é©¬é£</strong>*ï¼Œææ˜ç£Šï¼Œæ€€å®å…´ã€‚ä¸€ç§è™šæ‹Ÿå¯¹è±¡çš„åŠ¨ä½œå›¾åƒæ•°æ®ç”Ÿæˆæ–¹æ³•ã€è£…ç½®åŠç›¸å…³è®¾å¤‡ã€‚202310489294.8

<span class='anchor' id='-lwzl'></span>
# ğŸ‘¥ Research Team

| Role                  | Members (Affiliation)                                                                 |
| :-------------------: | :-----------------------------------------------------------------------------------: |
| **Engineers**         | Hongbo Xu, Yiyao Zhuo, Minghui Li                                                    |
| **PhD Students**      | He Hu (SZU), Yihong Ji (SZU), Zebang Cheng (SZU)                                     |
| **Master Students**   | Guojiang Li (SZU), Hao Yu (SZU)                                                      |
| **Interns/Visiting**  | Yifan Xie (THU PhD), Xiaotong Luo (XMU PhD), Yi Zhang (CityUHK PhD),<br>Jiyue Jiang (CUHK PhD), Haiwei Xue (THU Master),<br>Yu Wang (SYSU Master), Ledong An (TJU Master), Qinda Liu (TJU Master) |

<span class='anchor' id='-ryjx'></span>
# ğŸŒ Other Activities
- **Program Committee Member / Reviewer:**

&emsp;&emsp;<strong>Journals</strong>:Â  IEEE Transactions on Human-Machine Systems, Pattern Recognition, Computers in Industry, Software: Practice and Experience

&emsp;&emsp;<strong>Conferences</strong>:Â Conference on Neural Information Processing Systems (NeurIPS), International Conference on Learning Representations (ICLR), Conference on Computer Vision and Pattern Recognition (CVPR), ACM Multimedia, International Conference on Acoustics, Speech, and Signal Processing (ICASSP), IEEE International Conference on Multimedia & Expo (ICME)

- **Teaching**:  

&emsp;&emsp;Machine Learning, Spring 2025, SZU

&emsp;&emsp;Social Psychology and Behavioral Big Data, Spring 2023, BNU Zhuhai